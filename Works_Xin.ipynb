{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d72e514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our libraries \n",
    "\n",
    "# Pandas and numpy for data wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Seaborn / matplotlib for visualization \n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Import the trees from sklearn\n",
    "from sklearn import tree\n",
    "\n",
    "# Helper function to split our data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Helper fuctions to evaluate our model.\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score, roc_auc_score \n",
    "\n",
    "# Helper function for hyper-parameter turning.\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Import our Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "\n",
    "# Import our Random Forest \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Library for visualizing our tree\n",
    "# If you get an error, run 'conda install python-graphviz' in your terminal\n",
    "import graphviz\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f34af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Project Dataset/Application_Data.csv')\n",
    "# ['NAME_CONTRACT_STATUS']=df['NAME_CONTRACT_STATUS'].astype(int)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896638fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the shape of the dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f5faac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for null\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a4e8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many duplicated row in the dataset\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c115b6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use matplotlib to virually shows that the differece between all types of application result\n",
    "import matplotlib\n",
    "sns.countplot(df.NAME_CONTRACT_STATUS)\n",
    "plt.xlabel(\"Contract Status\")\n",
    "plt.ylabel(\"Count of Contract Status\")\n",
    "plt.title(\"Distribution of Contract Status\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e521c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the cancled loan application cuz it does not make any contribution to our reseach topic\n",
    "# and mark Approved and Unused offers as approved since they got accepted\n",
    "# and mark Refused loan as 0\n",
    "df['NAME_CONTRACT_STATUS']=df['NAME_CONTRACT_STATUS'].replace('Approved', '1')\n",
    "df['NAME_CONTRACT_STATUS']=df['NAME_CONTRACT_STATUS'].replace('Refused', '0')\n",
    "df['NAME_CONTRACT_STATUS']=df['NAME_CONTRACT_STATUS'].replace('Unused offer', '1')\n",
    "df.drop(df[df['NAME_CONTRACT_STATUS'] =='Canceled'].index, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57aa18f7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# #since we are not yet interested in the reject reason, drop it for now\n",
    "# #'NAME_SELLER_INDUSTRY'\n",
    "# # we are not interested in how approved loan is paid back now, drop it\n",
    "# df.drop('NAME_PAYMENT_TYPE', axis=1, inplace=True)\n",
    "\n",
    "# df.drop(['SELLERPLACE_AREA','CNT_PAYMENT','DAYS_FIRST_DRAWING','DAYS_FIRST_DUE'\n",
    "#         ,'DAYS_LAST_DUE_1ST_VERSION','DAYS_LAST_DUE','DAYS_TERMINATION','NFLAG_INSURED_ON_APPROVAL'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ffa337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the Canceled loan still exist\n",
    "df['NAME_CONTRACT_STATUS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a86b6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the shape of the dataset again, obviously, the canceled data is dropped\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c6f7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the histogram again, we now only have approved abd refused application\n",
    "sns.countplot(df.NAME_CONTRACT_STATUS)\n",
    "plt.xlabel(\"Contract Status\")\n",
    "plt.ylabel(\"Count of Contract Status\")\n",
    "plt.title(\"Distribution of Contract Status\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b55b0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert text type data into numerical data\n",
    "# df = pd.get_dummies(df, columns=['NAME_CONTRACT_TYPE','WEEKDAY_APPR_PROCESS_START','FLAG_LAST_APPL_PER_CONTRACT',\n",
    "#                                  'NAME_CASH_LOAN_PURPOSE','NAME_TYPE_SUITE','NAME_CLIENT_TYPE',\n",
    "#                                 'NAME_GOODS_CATEGORY','NAME_PORTFOLIO','NAME_PRODUCT_TYPE',\n",
    "#                                 'CHANNEL_TYPE','NAME_YIELD_GROUP','PRODUCT_COMBINATION','NFLAG_INSURED_ON_APPROVAL'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfda110",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calculate meta-data to identify % of data is missing in each column\n",
    "def meta_data(data):\n",
    "    total = data.isnull().sum()\n",
    "    percent = (data.isnull().sum()/data.isnull().count()*100)\n",
    "    unique = data.nunique()\n",
    "    datatypes = data.dtypes\n",
    "    return pd.concat([total, percent, unique, datatypes], axis=1, keys=['Total', 'Percent', 'Unique', 'Data_Type']).sort_values(by=\"Percent\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d6e5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating meta-data for application_data\n",
    "app_meta_data=meta_data(df)\n",
    "app_meta_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f30a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping columns with more than 57% missing values \n",
    "#Selected 57% because we don't want to drop EXT_SOURCE_1 which is an important variable\n",
    "cols_to_keep=list(app_meta_data[(app_meta_data.Percent<57)].index)\n",
    "application_data=df[cols_to_keep]\n",
    "application_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c2bfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#deal with missing AMT_ANNUITY values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4c9909",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"NAME_CONTRACT_STATUS\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6f8e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the average annuity of approved applications and refused applications\n",
    "average_approved_AMT_ANNUITY=(df[(df['NAME_CONTRACT_STATUS']=='Approved')])['AMT_ANNUITY'].mean()\n",
    "average_Refused_ANNUITY=(df[(df['NAME_CONTRACT_STATUS']=='Refused')])['AMT_ANNUITY'].mean()\n",
    "print(\"the average annuity of approved applications is \", average_approved_AMT_ANNUITY)\n",
    "print(\"the average annuity of refused applications is \", average_Refused_ANNUITY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73735c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#it seems like we have to fill something into the null values\n",
    "#some AMT_ANNUITY is empty, I will replace the the average AMT_ANNUITY based on its NAME_CONTRACT_STATUS\n",
    "\n",
    "df['AMT_ANNUITY'] = np.where(((df['AMT_ANNUITY'].isnull()==True) & (df['NAME_CONTRACT_STATUS'] == '1') ), average_approved_AMT_ANNUITY,df['AMT_ANNUITY'] )\n",
    "df['AMT_ANNUITY'] = np.where(((df['AMT_ANNUITY'].isnull()==True) & (df['NAME_CONTRACT_STATUS'] == '0') ), average_Refused_ANNUITY,df['AMT_ANNUITY'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b9c8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(30)\n",
    "#AMT_ANNUITY data are all filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172eddca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the row that miss AMT_CREDIT data\n",
    "df = df.dropna( how='any',subset=['AMT_CREDIT'])\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f847be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AMT_DOWN_PAYMENT'] = np.where(((df['AMT_DOWN_PAYMENT'].isnull()==True) ), 0,df['AMT_DOWN_PAYMENT'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87b52ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['OWN_CAR_AGE'] = np.where(((df['OWN_CAR_AGE'].isnull()==True) ), 0,df['OWN_CAR_AGE'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0871dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['OCCUPATION_TYPE'] = np.where(((df['OCCUPATION_TYPE'].isnull()==True) ), 'No Specified',df['OWN_CAR_AGE'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ca16e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CNT_FAM_MEMBERS'] = np.where(((df['CNT_FAM_MEMBERS'].isnull()==True) ), 'No Specified',df['CNT_FAM_MEMBERS'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25fe11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbfd4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949f716f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna( how='any',subset=['CODE_GENDER'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01bfd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna( how='any',subset=['AMT_GOODS_PRICE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982938b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna( how='any',subset=['CNT_PAYMENT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d99e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2d3eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['NAME_TYPE_SUITE'] = np.where(((df['NAME_TYPE_SUITE'].isnull()==True) ), 'No Specified',df['NAME_TYPE_SUITE'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f181a6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # make missing downpayments to zero\n",
    "# #delete\n",
    "# df['AMT_DOWN_PAYMENT'] = np.where(((df['AMT_DOWN_PAYMENT'].isnull()==True)), 0,df['AMT_DOWN_PAYMENT'])\n",
    "# df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be47081f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#client might not tell the goods' price, so just keep missing AMT_GOODS_PRICE values empty "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a2d792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #make missing RATE_DOWN_PAYMENT to zero since the AMT_DOWN_PAYMENT is zero\n",
    "# df['AMT_DOWN_PAYMENT'] = np.where(((df['RATE_DOWN_PAYMENT'].isnull()==True)), 0,df['RATE_DOWN_PAYMENT'])\n",
    "# df.isnull().sum()\n",
    "# df=df.drop(['AMT_DOWN_PAYMENT','AMT_DOWN_PAYMENT'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb059fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many types of loan types?\n",
    "sns.countplot(df.NAME_CONTRACT_TYPE)\n",
    "plt.xlabel(\"Contract Status\")\n",
    "plt.ylabel(\"Count of Contract Status\")\n",
    "plt.title(\"Distribution of Contract Status\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843b7bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete rows which has missing NAME_TYPE_SUITE and NFLAG_INSURED_ON_APPROVAL\n",
    "# missing NAME_TYPE_SUITE means the borrower does not tell Who accompanied client when \n",
    "# applying for the loan application, and missing NFLAG_INSURED_ON_APPROVAL means borrower does\n",
    "# not say about weather he requested insurance during the loan application\n",
    "df.dropna(subset=['NAME_TYPE_SUITE','AMT_GOODS_PRICE'],inplace=True)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06717303",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(df.NAME_CONTRACT_STATUS)\n",
    "plt.xlabel(\"Contract Status\")\n",
    "plt.ylabel(\"Count of Contract Status\")\n",
    "plt.title(\"Distribution of Contract Status\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da43f9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the total amount of approved and refused applications\n",
    "approved=df[df.NAME_CONTRACT_STATUS=='1']\n",
    "refused=df[df.NAME_CONTRACT_STATUS=='0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7a4e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the percentage\n",
    "percentage_approved=(len(approved)*100)/len(df)\n",
    "percentage_refused=(len(refused)*100)/len(df)\n",
    "print(\"The Percentage of people whose loans have been Approved is:\",round(percentage_approved,3),\"%\")\n",
    "print(\"The Percentage of people whose loans have been Refused is:\",round(percentage_refused,3),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7329c5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build a function to disaply the numbers of value in a column sorted by refused and approved \n",
    "#applications\n",
    "def plot_charts(var, label_rotation,horizontal_layout):\n",
    "    if(horizontal_layout):\n",
    "        fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(15,5))\n",
    "    else:\n",
    "        fig, (ax1, ax2) = plt.subplots(nrows=2, figsize=(15,30))\n",
    "    \n",
    "    s1=sns.countplot(ax=ax1,x=refused[var], data=refused, order= refused[var].value_counts().index,)\n",
    "    ax1.set_title(\"Refused\", fontsize=10)\n",
    "    ax1.set_xlabel('%s' %var)\n",
    "    ax1.set_ylabel(\"Count of Loans\")\n",
    "    if(label_rotation):\n",
    "        s1.set_xticklabels(s1.get_xticklabels(),rotation=90)\n",
    "    \n",
    "    s2=sns.countplot(ax=ax2,x=approved[var], data=approved, order= approved[var].value_counts().index,)\n",
    "    if(label_rotation):\n",
    "        s2.set_xticklabels(s2.get_xticklabels(),rotation=90)\n",
    "    ax2.set_xlabel('%s' %var)\n",
    "    ax2.set_ylabel(\"Count of Loans\")\n",
    "    ax2.set_title(\"Approved\", fontsize=10)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c926e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select_dtypes('object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8f152b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_charts('PRODUCT_COMBINATION', label_rotation=True,horizontal_layout=True)\n",
    "#we can see that most applications got refused because those borrows just ask for cash\n",
    "#and most approved application is for mortgage and mobile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f926f5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_charts('NAME_YIELD_GROUP', label_rotation=True,horizontal_layout=True)\n",
    "#we can see low interest rate application is likely to get refused."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c061275",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_charts('NAME_SELLER_INDUSTRY', label_rotation=True,horizontal_layout=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747055e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_charts('NAME_CASH_LOAN_PURPOSE', label_rotation=True,horizontal_layout=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d92fd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.pairplot(df, hue='NAME_CONTRACT_STATUS');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07e1fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #drop interest rate column since most of them are missing\n",
    "# df = df.drop('RATE_INTEREST_PRIMARY', 1)\n",
    "# df = df.drop('RATE_INTEREST_PRIVILEGED', 1)\n",
    "# df = df.drop('SK_ID_PREV', 1)\n",
    "df = df.drop('SK_ID_CURR', 1)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fb969b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['NFLAG_LAST_APPL_IN_DAY','NFLAG_LAST_APPL_IN_DAY'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e1f2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['PRODUCT_COMBINATION','PRODUCT_COMBINATION'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe205229",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['NAME_CASH_LOAN_PURPOSE','NAME_CASH_LOAN_PURPOSE'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad39a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['NAME_PAYMENT_TYPE','NAME_PAYMENT_TYPE'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc9acd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['REGION_POPULATION_RELATIVE','REGION_POPULATION_RELATIVE'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20a083c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['DAYS_REGISTRATION','DAYS_REGISTRATION'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c0e62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['AMT_ANNUITY','AMT_ANNUITY'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f133fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['AMT_CREDIT','AMT_CREDIT'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f31abab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['OCCUPATION_TYPE','OCCUPATION_TYPE'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5503e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['FLAG_WORK_PHONE','FLAG_WORK_PHONE'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d606ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f7c031",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['NAME_YIELD_GROUP'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afb5fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CNT_PAYMENT'].value_counts()\n",
    "x=0;\n",
    "for i in df['CNT_PAYMENT']:\n",
    "    if i>x:\n",
    "        x=i\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809de84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12385bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CODE_GENDER'] = np.where(((df['CODE_GENDER']=='M') ), '1','0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcc363e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FLAG_OWN_CAR'] = np.where(((df['FLAG_OWN_CAR']=='Y') ), '1','0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b87dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FLAG_OWN_REALTY'] = np.where(((df['FLAG_OWN_REALTY']=='Y') ), '1','0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcc328a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['NAME_INCOME_TYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaec244",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['NAME_EDUCATION_TYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc008154",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['NAME_FAMILY_STATUS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907a13e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['NAME_HOUSING_TYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b940c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['NAME_CONTRACT_TYPE','WEEKDAY_APPR_PROCESS_START','NAME_TYPE_SUITE',\n",
    "                                'NAME_CLIENT_TYPE','NAME_GOODS_CATEGORY','NAME_SELLER_INDUSTRY','NAME_INCOME_TYPE',\n",
    "                                 'NAME_EDUCATION_TYPE','NAME_FAMILY_STATUS','NAME_HOUSING_TYPE','NAME_YIELD_GROUP'\n",
    "                                ], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac0fe89",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for col_name in df.columns: \n",
    "    print(f\"'{col_name}',\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a650e2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare datas for build\n",
    "selected_features = ['AMT_APPLICATION',\n",
    "'AMT_DOWN_PAYMENT',\n",
    "'AMT_GOODS_PRICE',\n",
    "'HOUR_APPR_PROCESS_START',\n",
    "'NAME_CONTRACT_STATUS',\n",
    "'CNT_PAYMENT',\n",
    "'CODE_GENDER',\n",
    "'FLAG_OWN_CAR',\n",
    "'FLAG_OWN_REALTY',\n",
    "'CNT_CHILDREN',\n",
    "'AMT_INCOME_TOTAL',\n",
    "'DAYS_BIRTH',\n",
    "'DAYS_EMPLOYED',\n",
    "'OWN_CAR_AGE',\n",
    "'FLAG_MOBIL',\n",
    "'FLAG_EMAIL',\n",
    "'CNT_FAM_MEMBERS',\n",
    "'NAME_CONTRACT_TYPE_Consumer loans',\n",
    "'NAME_CONTRACT_TYPE_Revolving loans',\n",
    "'WEEKDAY_APPR_PROCESS_START_MONDAY',\n",
    "'WEEKDAY_APPR_PROCESS_START_SATURDAY',\n",
    "'WEEKDAY_APPR_PROCESS_START_SUNDAY',\n",
    "'WEEKDAY_APPR_PROCESS_START_THURSDAY',\n",
    "'WEEKDAY_APPR_PROCESS_START_TUESDAY',\n",
    "'WEEKDAY_APPR_PROCESS_START_WEDNESDAY',\n",
    "'NAME_TYPE_SUITE_Family',\n",
    "'NAME_TYPE_SUITE_Group of people',\n",
    "'NAME_TYPE_SUITE_No Specified',\n",
    "'NAME_TYPE_SUITE_Other_A',\n",
    "'NAME_TYPE_SUITE_Other_B',\n",
    "'NAME_TYPE_SUITE_Spouse, partner',\n",
    "'NAME_TYPE_SUITE_Unaccompanied',\n",
    "'NAME_CLIENT_TYPE_Refreshed',\n",
    "'NAME_CLIENT_TYPE_Repeater',\n",
    "'NAME_CLIENT_TYPE_XNA',\n",
    "'NAME_GOODS_CATEGORY_Animals',\n",
    "'NAME_GOODS_CATEGORY_Audio/Video',\n",
    "'NAME_GOODS_CATEGORY_Auto Accessories',\n",
    "'NAME_GOODS_CATEGORY_Clothing and Accessories',\n",
    "'NAME_GOODS_CATEGORY_Computers',\n",
    "'NAME_GOODS_CATEGORY_Construction Materials',\n",
    "'NAME_GOODS_CATEGORY_Consumer Electronics',\n",
    "'NAME_GOODS_CATEGORY_Direct Sales',\n",
    "'NAME_GOODS_CATEGORY_Education',\n",
    "'NAME_GOODS_CATEGORY_Fitness',\n",
    "'NAME_GOODS_CATEGORY_Furniture',\n",
    "'NAME_GOODS_CATEGORY_Gardening',\n",
    "'NAME_GOODS_CATEGORY_Homewares',\n",
    "'NAME_GOODS_CATEGORY_Insurance',\n",
    "'NAME_GOODS_CATEGORY_Jewelry',\n",
    "'NAME_GOODS_CATEGORY_Medical Supplies',\n",
    "'NAME_GOODS_CATEGORY_Medicine',\n",
    "'NAME_GOODS_CATEGORY_Mobile',\n",
    "'NAME_GOODS_CATEGORY_Office Appliances',\n",
    "'NAME_GOODS_CATEGORY_Other',\n",
    "'NAME_GOODS_CATEGORY_Photo / Cinema Equipment',\n",
    "'NAME_GOODS_CATEGORY_Sport and Leisure',\n",
    "'NAME_GOODS_CATEGORY_Tourism',\n",
    "'NAME_GOODS_CATEGORY_Vehicles',\n",
    "'NAME_GOODS_CATEGORY_Weapon',\n",
    "'NAME_GOODS_CATEGORY_XNA',\n",
    "'NAME_SELLER_INDUSTRY_Clothing',\n",
    "'NAME_SELLER_INDUSTRY_Connectivity',\n",
    "'NAME_SELLER_INDUSTRY_Construction',\n",
    "'NAME_SELLER_INDUSTRY_Consumer electronics',\n",
    "'NAME_SELLER_INDUSTRY_Furniture',\n",
    "'NAME_SELLER_INDUSTRY_Industry',\n",
    "'NAME_SELLER_INDUSTRY_Jewelry',\n",
    "'NAME_SELLER_INDUSTRY_MLM partners',\n",
    "'NAME_SELLER_INDUSTRY_Tourism',\n",
    "'NAME_SELLER_INDUSTRY_XNA',\n",
    "'NAME_INCOME_TYPE_Maternity leave',\n",
    "'NAME_INCOME_TYPE_Pensioner',\n",
    "'NAME_INCOME_TYPE_State servant',\n",
    "'NAME_INCOME_TYPE_Student',\n",
    "'NAME_INCOME_TYPE_Unemployed',\n",
    "'NAME_INCOME_TYPE_Working',\n",
    "'NAME_EDUCATION_TYPE_Higher education',\n",
    "'NAME_EDUCATION_TYPE_Incomplete higher',\n",
    "'NAME_EDUCATION_TYPE_Lower secondary',\n",
    "'NAME_EDUCATION_TYPE_Secondary / secondary special',\n",
    "'NAME_FAMILY_STATUS_Married',\n",
    "'NAME_FAMILY_STATUS_Separated',\n",
    "'NAME_FAMILY_STATUS_Single / not married',\n",
    "'NAME_FAMILY_STATUS_Widow',\n",
    "'NAME_HOUSING_TYPE_House / apartment',\n",
    "'NAME_HOUSING_TYPE_Municipal apartment',\n",
    "'NAME_HOUSING_TYPE_Office apartment',\n",
    "'NAME_HOUSING_TYPE_Rented apartment',\n",
    "'NAME_HOUSING_TYPE_With parents',\n",
    "'NAME_YIELD_GROUP_high',\n",
    "'NAME_YIELD_GROUP_low_action',\n",
    "'NAME_YIELD_GROUP_low_normal',\n",
    "'NAME_YIELD_GROUP_middle']\n",
    "\n",
    "X = df[selected_features]\n",
    "y = df['NAME_CONTRACT_STATUS']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=45)\n",
    "print('Lenght of our Training data:', X_train.shape, '\\nLength of our Testing data:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b97601",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['NAME_CONTRACT_STATUS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec22a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3a471d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef188b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a84d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c640cd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier \n",
    "\n",
    "\n",
    "model = DecisionTreeClassifier(max_depth=9)\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "print(\"Accuracy Score: %f\" % accuracy)\n",
    "\n",
    "precision = precision_score(y_true=y_test, y_pred=y_pred,pos_label='1')\n",
    "print(\"Precision Score: %f\" % precision)\n",
    "\n",
    "recall = recall_score(y_true=y_test, y_pred=y_pred, pos_label='1')\n",
    "print(\"Recall Score: %f\" % recall)\n",
    "\n",
    "f1 = f1_score(y_true=y_test, y_pred=y_pred,pos_label='1')\n",
    "print('F1 Score: %f' % f1)\n",
    "\n",
    "\n",
    "# Calculate predicted probabilities\n",
    "y_pred_proba = model.predict_proba(X_test)\n",
    "\n",
    "# # Keep only the proba for True\n",
    "y_pred_proba = y_pred_proba[:,1]\n",
    "\n",
    "# # Compute auc score\n",
    "auc = roc_auc_score(y_true=y_test, y_score=y_pred_proba)\n",
    "\n",
    "print('AUC Score: %f' % auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53cf9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = tree.export_graphviz(model, out_file=None, \n",
    "                     feature_names=selected_features,\n",
    "                     class_names=['Approved','refused'],\n",
    "                     filled=True, rounded=True,  \n",
    "                     special_characters=True)  \n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9e0820",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Now lets look at our feature importances\n",
    "my_dict = {'feature_importance': model.feature_importances_,\n",
    "           'feature':selected_features }\n",
    "feature_imp = pd.DataFrame.from_dict( my_dict ).sort_values('feature_importance', ascending=False)\n",
    "feature_imp\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4372d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty Random Forest model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Now lets evaluate our model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "print(\"Accuracy Score: %f\" % accuracy)\n",
    "\n",
    "precision = precision_score(y_true=y_test, y_pred=y_pred, pos_label='1')\n",
    "print(\"Precision Score: %f\" % precision)\n",
    "\n",
    "recall = recall_score(y_true=y_test, y_pred=y_pred, pos_label='1')\n",
    "print(\"Recall Score: %f\" % recall)\n",
    "\n",
    "f1 = f1_score(y_true=y_test, y_pred=y_pred, pos_label='1')\n",
    "print('F1 Score: %f' % f1)\n",
    "\n",
    "# Calculate predicted probabilities, keep only probability for when class = 1\n",
    "y_pred_proba = model.predict_proba(X_test)[:,1]\n",
    "auc = roc_auc_score(y_true=y_test, y_score=y_pred_proba)\n",
    "print('AUC Score: %f' % auc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391439d2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05119838",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "params = {\n",
    "    'n_estimators' : [5, 10, 50, 100],\n",
    "    'criterion' : ['gini', 'entropy'],\n",
    "    'max_depth': [5, 10, 20], \n",
    "    'min_samples_split': [2, 10, 100],\n",
    "    'max_features': [2, 4, 'auto']\n",
    "}\n",
    "\n",
    "grid_search_cv = GridSearchCV( \n",
    "    estimator=RandomForestClassifier(), \n",
    "    param_grid=params,\n",
    "    scoring='f1', )\n",
    "\n",
    "\n",
    "# Now, with one easy command, fit all combination of trees. \n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Print the best parameters it found\n",
    "print(grid_search_cv.best_params_)\n",
    "\n",
    "\n",
    "# This command gives you model that has the highest f1-score. \n",
    "model = grid_search_cv.best_estimator_\n",
    "\n",
    "# Now lets evaluate our model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "print(\"Accuracy Score: %f\" % accuracy)\n",
    "\n",
    "precision = precision_score(y_true=y_test, y_pred=y_pred, pos_label='1')\n",
    "print(\"Precision Score: %f\" % precision)\n",
    "\n",
    "recall = recall_score(y_true=y_test, y_pred=y_pred, pos_label='1')\n",
    "print(\"Recall Score: %f\" % recall)\n",
    "\n",
    "f1 = f1_score(y_true=y_test, y_pred=y_pred, pos_label='1')\n",
    "print('F1 Score: %f' % f1)\n",
    "\n",
    "# Calculate predicted probabilities, keep only probability for when class = 1\n",
    "y_pred_proba = model.predict_proba(X_test)[:,1]\n",
    "auc = roc_auc_score(y_true=y_test, y_score=y_pred_proba)\n",
    "print('AUC Score: %f' % auc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f1f3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting the loan amount range\n",
    "# will have delete the refused data, and delete the application_result column\n",
    "# and treat loan_amount as our new y data\n",
    "df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20050962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop refused data\n",
    "df.drop(df[df['NAME_CONTRACT_STATUS']=='Refused'].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a39c495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete NAME_CONTRACT_STATUS column\n",
    "df = df.drop('NAME_CONTRACT_STATUS', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9088813c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc52b402",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AMT_CREDIT'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffb447e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Now lets look at our feature importances\n",
    "my_dict = {'feature_importance': model.feature_importances_,\n",
    "           'feature':selected_features }\n",
    "feature_imp = pd.DataFrame.from_dict( my_dict ).sort_values('feature_importance', ascending=False)\n",
    "feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f55191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "original_cols = df.columns\n",
    "\n",
    "target_cols = ['AMT_ANNUITY',\n",
    "'AMT_APPLICATION',\n",
    "'AMT_GOODS_PRICE',\n",
    "'HOUR_APPR_PROCESS_START',\n",
    "'NFLAG_LAST_APPL_IN_DAY',\n",
    "'DAYS_DECISION',\n",
    "'NAME_CONTRACT_TYPE_Consumer loans',\n",
    "'NAME_CONTRACT_TYPE_Revolving loans']\n",
    "\n",
    "z_score_cols = []\n",
    "\n",
    "# Loop through our target columns\n",
    "for col in target_cols:\n",
    "    # Make the new column name the same as the original but with 'z_score' added to it\n",
    "    new_col_name = col + \"_zscore\"\n",
    "    \n",
    "    # Set the new column equal to the score\n",
    "    df[new_col_name] = stats.stats.zscore( df[col] )\n",
    "    \n",
    "    # Set the z-score to its absolute value of the for easier filtering\n",
    "    df[new_col_name] = abs( df[new_col_name] )\n",
    "    \n",
    "    # Append the new column name our our z_score_cols list for easier access for later.\n",
    "    z_score_cols.append(new_col_name)\n",
    "\n",
    "\n",
    "condition = df[z_score_cols] < 3\n",
    "print(df.shape)\n",
    "\n",
    "# # Say TRUE only if all of the rows are True, else return False\n",
    "condition = condition.all(axis=1)\n",
    "\n",
    "print('Before removal of outliers', df.shape)\n",
    "\n",
    "df = df[condition]\n",
    "\n",
    "print('After removal of outliers', df.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb8db96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[original_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc237a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Now lets evaluate our model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "print(\"Accuracy Score: %f\" % accuracy)\n",
    "\n",
    "precision = precision_score(y_true=y_test, y_pred=y_pred, pos_label='1')\n",
    "print(\"Precision Score: %f\" % precision)\n",
    "\n",
    "recall = recall_score(y_true=y_test, y_pred=y_pred, pos_label='1')\n",
    "print(\"Recall Score: %f\" % recall)\n",
    "\n",
    "f1 = f1_score(y_true=y_test, y_pred=y_pred, pos_label='1')\n",
    "print('F1 Score: %f' % f1)\n",
    "\n",
    "# Calculate predicted probabilities, keep only probability for when class = 1\n",
    "y_pred_proba = model.predict_proba(X_test)[:,1]\n",
    "auc = roc_auc_score(y_true=y_test, y_score=y_pred_proba)\n",
    "print('AUC Score: %f' % auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28829bf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
